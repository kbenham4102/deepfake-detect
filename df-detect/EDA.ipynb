{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd \n",
    "from tensorflow.keras.layers import ConvLSTM2D, Conv3D, Conv2D, Flatten, Dense, BatchNormalization\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from video_loader import DeepFakeTransformer\n",
    "import sys\n",
    "import pathlib\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train params\n",
    "EPOCHS=10\n",
    "batch_size=2\n",
    "epoch_steps = 1000\n",
    "val_steps = 1000\n",
    "reg_penalty = 0.001\n",
    "cls_wt = {0:3, 1:2.25}\n",
    "\n",
    "# Dataset params\n",
    "data_pairs_path = '../data/source/labels/fake_to_real_mapping.csv'\n",
    "resize_shape = (224,224)\n",
    "sequence_len = 30\n",
    "prefetch_num = 10\n",
    "train_val_split = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.read_csv(data_pairs_path)[['real', 'fake']]\n",
    "\n",
    "train_df, val_df = train_test_split(df_pairs, test_size = train_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69277\n",
      "1055\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../data/source/train_val_sort/train/REAL/clcjjbtmnm.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/qsdjaqcmzl.mp4'],\n",
       "       ['../data/source/train_val_sort/train/REAL/sdzzjnfxtw.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/sbyckvrrlz.mp4'],\n",
       "       ['../data/source/train_val_sort/train/REAL/nzrcmggcfp.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/mamywmhzvm.mp4'],\n",
       "       ...,\n",
       "       ['../data/source/train_val_sort/train/REAL/rjlgchzmfv.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/uwnwipuzvk.mp4'],\n",
       "       ['../data/source/train_val_sort/train/REAL/crmobgizwo.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/prykceywau.mp4'],\n",
       "       ['../data/source/train_val_sort/train/REAL/fuusxfhmrc.mp4',\n",
       "        '../data/source/train_val_sort/train/FAKE/mgkkbmfumw.mp4']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'../data/source/train_val_sort/train/REAL/clcjjbtmnm.mp4'\n",
      " b'../data/source/train_val_sort/train/FAKE/qsdjaqcmzl.mp4'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for f in train_ds.take(1):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    \"\"\"Helper class for reading one or more frames from a video file.\"\"\"\n",
    "\n",
    "    def __init__(self, verbose=True, insets=(0, 0)):\n",
    "        \"\"\"Creates a new VideoReader.\n",
    "\n",
    "        Arguments:\n",
    "            verbose: whether to print warnings and error messages\n",
    "            insets: amount to inset the image by, as a percentage of \n",
    "                (width, height). This lets you \"zoom in\" to an image \n",
    "                to remove unimportant content around the borders. \n",
    "                Useful for face detection, which may not work if the \n",
    "                faces are too small.\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.insets = insets\n",
    "    \n",
    "    def read_frames_test(self, path, num_frames, jitter=0, seed=None):\n",
    "        \"\"\"Reads frames that are always evenly spaced throughout the video.\n",
    "\n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            num_frames: how many frames to read, -1 means the entire video\n",
    "                (warning: this will take up a lot of memory!)\n",
    "            jitter: if not 0, adds small random offsets to the frame indices;\n",
    "                this is useful so we don't always land on even or odd frames\n",
    "            seed: random seed for jittering; if you set this to a fixed value,\n",
    "                you probably want to set it only on the first video \n",
    "        \"\"\"\n",
    "\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frame_idxs = np.linspace(0, frame_count - 1, frame_count, endpoint=True, dtype=np.int)\n",
    "        if jitter > 0:\n",
    "            np.random.seed(seed)\n",
    "            jitter_offsets = np.random.randint(-jitter, jitter, len(frame_idxs))\n",
    "            frame_idxs = np.clip(frame_idxs + jitter_offsets, 0, frame_count - 1)\n",
    "\n",
    "        result, _ = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "\n",
    "    def read_frames(self, path, num_frames, jitter=0, seed=None):\n",
    "        \"\"\"Reads frames that are always evenly spaced throughout the video.\n",
    "\n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            num_frames: how many frames to read\n",
    "            jitter: if not 0, adds small random offsets to the frame indices;\n",
    "                this is useful so we don't always land on even or odd frames\n",
    "            seed: random seed for jittering; if you set this to a fixed value,\n",
    "                you probably want to set it only on the first video \n",
    "        \"\"\"\n",
    "        assert num_frames > 0\n",
    "\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if frame_count <= 0: return None\n",
    "\n",
    "        start = np.random.randint(frame_count-num_frames)\n",
    "        frame_idxs = np.linspace(start, start+num_frames, num=num_frames, dtype=np.int)\n",
    "        if jitter > 0:\n",
    "            np.random.seed(seed)\n",
    "            jitter_offsets = np.random.randint(-jitter, jitter, len(frame_idxs))\n",
    "            frame_idxs = np.clip(frame_idxs + jitter_offsets, 0, frame_count - 1)\n",
    "\n",
    "        result, _ = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_random_frames(self, path, num_frames, seed=None):\n",
    "        \"\"\"Picks the frame indices at random.\n",
    "        \n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            num_frames: how many frames to read, -1 means the entire video\n",
    "                (warning: this will take up a lot of memory!)\n",
    "        \"\"\"\n",
    "        assert num_frames > 0\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if frame_count <= 0: return None\n",
    "\n",
    "        frame_idxs = sorted(np.random.choice(np.arange(0, frame_count), num_frames))\n",
    "        result = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_frames_at_indices(self, path, frame_idxs):\n",
    "        \"\"\"Reads frames from a video and puts them into a NumPy array.\n",
    "\n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            frame_idxs: a list of frame indices. Important: should be\n",
    "                sorted from low-to-high! If an index appears multiple\n",
    "                times, the frame is still read only once.\n",
    "\n",
    "        Returns:\n",
    "            - a NumPy array of shape (num_frames, height, width, 3)\n",
    "            - a list of the frame indices that were read\n",
    "\n",
    "        Reading stops if loading a frame fails, in which case the first\n",
    "        dimension returned may actually be less than num_frames.\n",
    "\n",
    "        Returns None if an exception is thrown for any reason, or if no\n",
    "        frames were read.\n",
    "        \"\"\"\n",
    "        assert len(frame_idxs) > 0\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        result = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def _read_frames_at_indices(self, path, capture, frame_idxs):\n",
    "        try:\n",
    "            frames = []\n",
    "            idxs_read = []\n",
    "            for frame_idx in range(frame_idxs[0], frame_idxs[-1] + 1):\n",
    "                # Get the next frame, but don't decode if we're not using it.\n",
    "                ret = capture.grab()\n",
    "                if not ret:\n",
    "                    if self.verbose:\n",
    "                        print(\"Error grabbing frame %d from movie %s\" % (frame_idx, path))\n",
    "                    break\n",
    "\n",
    "                # Need to look at this frame?\n",
    "                current = len(idxs_read)\n",
    "                if frame_idx == frame_idxs[current]:\n",
    "                    ret, frame = capture.retrieve()\n",
    "                    if not ret or frame is None:\n",
    "                        if self.verbose:\n",
    "                            print(\"Error retrieving frame %d from movie %s\" % (frame_idx, path))\n",
    "                        break\n",
    "\n",
    "                    frame = self._postprocess_frame(frame)\n",
    "                    frames.append(frame)\n",
    "                    idxs_read.append(frame_idx)\n",
    "\n",
    "            if len(frames) > 0:\n",
    "                return np.stack(frames), idxs_read\n",
    "            if self.verbose:\n",
    "                print(\"No frames read from movie %s\" % path)\n",
    "            return None\n",
    "        except:\n",
    "            if self.verbose:\n",
    "                print(\"Exception while reading movie %s\" % path)\n",
    "            return None    \n",
    "\n",
    "    def read_middle_frame(self, path):\n",
    "        \"\"\"Reads the frame from the middle of the video.\"\"\"\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        result = self._read_frame_at_index(path, capture, frame_count // 2)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_frame_at_index(self, path, frame_idx):\n",
    "        \"\"\"Reads a single frame from a video.\n",
    "        \n",
    "        If you just want to read a single frame from the video, this is more\n",
    "        efficient than scanning through the video to find the frame. However,\n",
    "        for reading multiple frames it's not efficient.\n",
    "        \n",
    "        My guess is that a \"streaming\" approach is more efficient than a \n",
    "        \"random access\" approach because, unless you happen to grab a keyframe, \n",
    "        the decoder still needs to read all the previous frames in order to \n",
    "        reconstruct the one you're asking for.\n",
    "\n",
    "        Returns a NumPy array of shape (1, H, W, 3) and the index of the frame,\n",
    "        or None if reading failed.\n",
    "        \"\"\"\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        result = self._read_frame_at_index(path, capture, frame_idx)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def _read_frame_at_index(self, path, capture, frame_idx):\n",
    "        capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = capture.read()    \n",
    "        if not ret or frame is None:\n",
    "            if self.verbose:\n",
    "                print(\"Error retrieving frame %d from movie %s\" % (frame_idx, path))\n",
    "            return None\n",
    "        else:\n",
    "            frame = self._postprocess_frame(frame)\n",
    "            return np.expand_dims(frame, axis=0), [frame_idx]\n",
    "    \n",
    "    def _postprocess_frame(self, frame):\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # if self.insets[0] > 0:\n",
    "        #     W = frame.shape[1]\n",
    "        #     p = int(W * self.insets[0])\n",
    "        #     frame = frame[:, p:-p, :]\n",
    "\n",
    "        # if self.insets[1] > 0:\n",
    "        #     H = frame.shape[1]\n",
    "        #     q = int(H * self.insets[1])\n",
    "        #     frame = frame[q:-q, :, :]\n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeDualTransformer(object):\n",
    "    def __init__(self, chan_means=[0.485, 0.456, 0.406],\n",
    "                       chan_std_dev=[0.229, 0.224, 0.225],\n",
    "                       resize_shape=(300,300),\n",
    "                       seq_length=298,\n",
    "                       mode=\"train\"):\n",
    "        \"\"\"[summary]\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            chan_means {list} -- [description] (default: {[0.485, 0.456, 0.406]})\n",
    "            chan_std_dev {list} -- [description] (default: {[0.229, 0.224, 0.225]})\n",
    "            resize_shape {tuple} -- [description] (default: {(300,300)})\n",
    "            seq_length {int} -- [description] (default: {298})\n",
    "            mode {str} -- [description] (default: {\"train\"})\n",
    "        \"\"\"\n",
    "\n",
    "        self.chan_means = chan_means\n",
    "        self.chan_std_dev = chan_std_dev\n",
    "        self.resize_shape = resize_shape\n",
    "        self.seq_length = seq_length\n",
    "        self.mode = mode\n",
    "        self.reader = VideoReader()\n",
    "        \n",
    "    def get_frames(self, fnames):\n",
    "\n",
    "        num_frames = self.seq_length\n",
    "        \n",
    "        real = fnames.numpy()[0].decode('utf-8')\n",
    "        fake = fnames.numpy()[1].decode('utf-8')\n",
    "        \n",
    "        real_capture = cv2.VideoCapture(real)\n",
    "        fake_capture = cv2.VideoCapture(fake)\n",
    "        \n",
    "        \n",
    "        # Counts should be equal between real and fakes\n",
    "        frame_count = int(fake_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        # Base inds on same frame grab to use matching video frames\n",
    "        start = np.random.randint(frame_count-num_frames)\n",
    "        frame_idxs = np.linspace(start, start+num_frames, num=num_frames, dtype=np.int)\n",
    "        \n",
    "        real_vid, _ = self.reader._read_frames_at_indices(real, real_capture, frame_idxs)\n",
    "        fake_vid, _ = self.reader._read_frames_at_indices(fake, fake_capture, frame_idxs)\n",
    "        \n",
    "        real_capture.release()\n",
    "        fake_capture.release()\n",
    "        \n",
    "        return real_vid, fake_vid\n",
    "    \n",
    "    def normalize(self, video, chan_means, chan_std_dev):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Arguments:\n",
    "            video {tf.Tensor} -- tensorflow reshaped video data\n",
    "            chan_means {array} -- [description]\n",
    "            chan_std_dev {array} -- [description]\n",
    "\n",
    "        Returns:\n",
    "            [tf.Tensor] -- normalized video data\n",
    "        \"\"\"\n",
    "\n",
    "        video /= 255\n",
    "        video -= chan_means\n",
    "        video /= chan_std_dev\n",
    "\n",
    "        return video\n",
    "    \n",
    "    def transform_vid(self, filenames):\n",
    "\n",
    "        \n",
    "        chan_means = self.chan_means\n",
    "        chan_std_dev = self.chan_std_dev\n",
    "        resize_shape = self.resize_shape\n",
    "        \n",
    "        # For kaggle only\n",
    "        # fname = parts[-1].numpy().decode('utf-8')\n",
    "        # global filelog\n",
    "        # filelog.append(fname)\n",
    "        \n",
    "        real_vid, fake_vid = self.get_frames(filenames)\n",
    "        \n",
    "\n",
    "        real_vid = tf.image.resize(real_vid, size=resize_shape)\n",
    "        fake_vid = tf.image.resize(fake_vid, size=resize_shape)\n",
    "        real_vid = self.normalize(real_vid, chan_means, chan_std_dev)\n",
    "        fake_vid = self.normalize(fake_vid, chan_means, chan_std_dev)\n",
    "\n",
    "        return tf.stack((real_vid, fake_vid))\n",
    "    \n",
    "    def transform_map(self, x):\n",
    "        result_tensor = tf.py_function(func=self.transform_vid,\n",
    "                                        inp=[x],\n",
    "                                        Tout=[tf.float32])\n",
    "        result_tensor[0].set_shape((2,None,None,None,None))\n",
    "        return result_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nframes_test(path):\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    capture.release()\n",
    "    return frame_count\n",
    "    \n",
    "def _test_frames(df):\n",
    "\n",
    "    i = 0\n",
    "    for r,f in df.to_numpy():\n",
    "        fs = get_nframes_test(f)\n",
    "        rs = get_nframes_test(r)\n",
    "        i+=1\n",
    "        if i%100 == 0:\n",
    "            print('vids tested: ', i+1)\n",
    "        \n",
    "        if fs != rs:\n",
    "            print(r)\n",
    "            print(rs)\n",
    "            print(f)\n",
    "            print(fs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(train_df.to_numpy())\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(val_df.to_numpy())\n",
    "train_transformer = DeepFakeDualTransformer(resize_shape=resize_shape, seq_length=sequence_len)\n",
    "# TODO add in random crops, rotations, etc to make this non-redundant\n",
    "val_transformer = DeepFakeDualTransformer(resize_shape=resize_shape, seq_length=sequence_len)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: train_transformer.transform_map(x)).prefetch(prefetch_num)\n",
    "val_ds = val_ds.map(lambda x: val_transformer.transform_map(x)).prefetch(prefetch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trf = DeepFakeDualTransformer(resize_shape=resize_shape, seq_length=sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_trf.transform_vid(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30, 224, 224, 3)\n",
      "(2, 30, 224, 224, 3)\n",
      "(2, 30, 224, 224, 3)\n",
      "(2, 30, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for f1 in train_ds.as_numpy_iterator():\n",
    "    print(f1.shape)\n",
    "    i += 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
