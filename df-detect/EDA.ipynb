{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=1\n",
    "validate_epochs = [1,2,10]\n",
    "batch_size=1\n",
    "test_fraction = 0.2\n",
    "train_label_path = '../data/source/labels/train_meta.json'\n",
    "train_path = '../data/source/train/'\n",
    "checkpoint_prefix = 'models/ckpt_{epoch}'\n",
    "resize_shape = (224,224)\n",
    "sequence_len = 16\n",
    "n_workers = 1\n",
    "use_mult_prc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_root = '/home/kevin/deepfake-proj/data/source/train_val_sort/train/'\n",
    "vid_root = pathlib.Path(vid_root)\n",
    "vid_ds = tf.data.Dataset.list_files(str(vid_root/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/home/kevin/deepfake-proj/data/source/train_val_sort/train/FAKE/eukvucdetx.mp4'\n",
      "b'/home/kevin/deepfake-proj/data/source/train_val_sort/train/FAKE/ahfazfbntc.mp4'\n",
      "b'/home/kevin/deepfake-proj/data/source/train_val_sort/train/FAKE/awhmfnnjih.mp4'\n",
      "b'/home/kevin/deepfake-proj/data/source/train_val_sort/train/FAKE/dnhvalzvrt.mp4'\n",
      "b'/home/kevin/deepfake-proj/data/source/train_val_sort/train/REAL/ellavthztb.mp4'\n"
     ]
    }
   ],
   "source": [
    "for f in vid_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeTransformer(object):\n",
    "    def __init__(self, chan_means=[0.485, 0.456, 0.406],\n",
    "                       chan_std_dev=[0.229, 0.224, 0.225],\n",
    "                       resize_shape=(300,300),\n",
    "                       seq_length=298):\n",
    "        self.chan_means = chan_means\n",
    "        self.chan_std_dev = chan_std_dev\n",
    "        self.resize_shape = resize_shape\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def get_frames(filename):\n",
    "        '''\n",
    "        method for getting the frames from a video file\n",
    "        args: \n",
    "            filename: exact path of the video file\n",
    "            first_only: whether to detect the first frame only or all of the frames\n",
    "        out:\n",
    "            video_frames, label:  \n",
    "        '''\n",
    "\n",
    "        filepath = filename.numpy().decode('utf-8')\n",
    "\n",
    "\n",
    "        cap = cv2.VideoCapture(filepath) \n",
    "        # captures the video. Think of it as if life is a movie so we ask the method to focus on patricular event\n",
    "        # that is our video in this case. It will concentrate on the video\n",
    "        frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        all_frames = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "\n",
    "\n",
    "        fc = 0\n",
    "        while(cap.isOpened() and fc < frameCount): # as long as all the frames have been traversed\n",
    "            ret, frame = cap.read()\n",
    "            # capture the frame. Again, if life is a movie, this function acts as camera\n",
    "\n",
    "            if ret==True:\n",
    "                all_frames[fc] = frame\n",
    "                fc += 1\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'): # break in between by pressing the key given\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        # release whatever was held by the method for say, resources and the video itself\n",
    "        return all_frames\n",
    "\n",
    "    # tensorflow functions to pre-process videos\n",
    "    def normalize(video, chan_means, chan_std_dev):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Arguments:\n",
    "            video {tf.Tensor} -- tensorflow reshaped video data\n",
    "            chan_means {array} -- [description]\n",
    "            chan_std_dev {array} -- [description]\n",
    "\n",
    "        Returns:\n",
    "            [tf.Tensor] -- normalized video data\n",
    "        \"\"\"\n",
    "\n",
    "        video /= 255\n",
    "        video -= chan_means\n",
    "        video /= chan_std_dev\n",
    "\n",
    "        return video\n",
    "\n",
    "    def transform_vid(self, filename):\n",
    "        \n",
    "        chan_means = self.chan_means\n",
    "        chan_std_dev = self.chan_std_dev\n",
    "        resize_shape = self.resize_shape\n",
    "        seq_length = self.seq_length\n",
    " \n",
    "        parts = tf.strings.split(filename, '/')\n",
    "        label = parts[-2]\n",
    "        # Don't want to exceed frames, available, using 198 as limit\n",
    "        if seq_length == 298:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = np.random.randint(298 - seq_length)\n",
    "\n",
    "        vid = get_frames(filename)[start:(start+seq_length),:,:,:]\n",
    "        vid = tf.image.resize(vid, size=resize_shape).numpy()\n",
    "        vid = normalize(vid, chan_means, chan_std_dev)\n",
    "\n",
    "        return vid, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DeepFakeTransformer(resize_shape=(224,224))\n",
    "trf_func = transformer.transform_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vid_ds = vid_ds.map(lambda x: tf.py_function(trf_func, [x], [tf.float32, tf.string]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'REAL', shape=(), dtype=string)\n",
      "(298, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "for vid, label in vid_ds.take(1):\n",
    "    print(label)\n",
    "    print(vid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 224]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.resize_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dims = (batch_size, sequence_len, *resize_shape, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    \"\"\"Helper class for reading one or more frames from a video file.\"\"\"\n",
    "\n",
    "    def __init__(self, verbose=True, insets=(0, 0)):\n",
    "        \"\"\"Creates a new VideoReader.\n",
    "\n",
    "        Arguments:\n",
    "            verbose: whether to print warnings and error messages\n",
    "            insets: amount to inset the image by, as a percentage of \n",
    "                (width, height). This lets you \"zoom in\" to an image \n",
    "                to remove unimportant content around the borders. \n",
    "                Useful for face detection, which may not work if the \n",
    "                faces are too small.\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.insets = insets\n",
    "\n",
    "    def read_frames(self, path, num_frames, jitter=0, seed=None):\n",
    "        \"\"\"Reads frames that are always evenly spaced throughout the video.\n",
    "\n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            num_frames: how many frames to read, -1 means the entire video\n",
    "                (warning: this will take up a lot of memory!)\n",
    "            jitter: if not 0, adds small random offsets to the frame indices;\n",
    "                this is useful so we don't always land on even or odd frames\n",
    "            seed: random seed for jittering; if you set this to a fixed value,\n",
    "                you probably want to set it only on the first video \n",
    "        \"\"\"\n",
    "        assert num_frames > 0\n",
    "\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if frame_count <= 0: return None\n",
    "\n",
    "        start = np.random.randint(frame_count-num_frames)\n",
    "        frame_idxs = np.linspace(start, start+num_frames, num=num_frames, dtype=np.int)\n",
    "        if jitter > 0:\n",
    "            np.random.seed(seed)\n",
    "            jitter_offsets = np.random.randint(-jitter, jitter, len(frame_idxs))\n",
    "            frame_idxs = np.clip(frame_idxs + jitter_offsets, 0, frame_count - 1)\n",
    "\n",
    "        result = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_random_frames(self, path, num_frames, seed=None):\n",
    "        \"\"\"Picks the frame indices at random.\n",
    "        \n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            num_frames: how many frames to read, -1 means the entire video\n",
    "                (warning: this will take up a lot of memory!)\n",
    "        \"\"\"\n",
    "        assert num_frames > 0\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if frame_count <= 0: return None\n",
    "\n",
    "        frame_idxs = sorted(np.random.choice(np.arange(0, frame_count), num_frames))\n",
    "        result = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_frames_at_indices(self, path, frame_idxs):\n",
    "        \"\"\"Reads frames from a video and puts them into a NumPy array.\n",
    "\n",
    "        Arguments:\n",
    "            path: the video file\n",
    "            frame_idxs: a list of frame indices. Important: should be\n",
    "                sorted from low-to-high! If an index appears multiple\n",
    "                times, the frame is still read only once.\n",
    "\n",
    "        Returns:\n",
    "            - a NumPy array of shape (num_frames, height, width, 3)\n",
    "            - a list of the frame indices that were read\n",
    "\n",
    "        Reading stops if loading a frame fails, in which case the first\n",
    "        dimension returned may actually be less than num_frames.\n",
    "\n",
    "        Returns None if an exception is thrown for any reason, or if no\n",
    "        frames were read.\n",
    "        \"\"\"\n",
    "        assert len(frame_idxs) > 0\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        result = self._read_frames_at_indices(path, capture, frame_idxs)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def _read_frames_at_indices(self, path, capture, frame_idxs):\n",
    "        try:\n",
    "            frames = []\n",
    "            idxs_read = []\n",
    "            for frame_idx in range(frame_idxs[0], frame_idxs[-1] + 1):\n",
    "                # Get the next frame, but don't decode if we're not using it.\n",
    "                ret = capture.grab()\n",
    "                if not ret:\n",
    "                    if self.verbose:\n",
    "                        print(\"Error grabbing frame %d from movie %s\" % (frame_idx, path))\n",
    "                    break\n",
    "\n",
    "                # Need to look at this frame?\n",
    "                current = len(idxs_read)\n",
    "                if frame_idx == frame_idxs[current]:\n",
    "                    ret, frame = capture.retrieve()\n",
    "                    if not ret or frame is None:\n",
    "                        if self.verbose:\n",
    "                            print(\"Error retrieving frame %d from movie %s\" % (frame_idx, path))\n",
    "                        break\n",
    "\n",
    "                    frame = self._postprocess_frame(frame)\n",
    "                    frames.append(frame)\n",
    "                    idxs_read.append(frame_idx)\n",
    "\n",
    "            if len(frames) > 0:\n",
    "                return np.stack(frames), idxs_read\n",
    "            if self.verbose:\n",
    "                print(\"No frames read from movie %s\" % path)\n",
    "            return None\n",
    "        except:\n",
    "            if self.verbose:\n",
    "                print(\"Exception while reading movie %s\" % path)\n",
    "            return None    \n",
    "\n",
    "    def read_middle_frame(self, path):\n",
    "        \"\"\"Reads the frame from the middle of the video.\"\"\"\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        result = self._read_frame_at_index(path, capture, frame_count // 2)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def read_frame_at_index(self, path, frame_idx):\n",
    "        \"\"\"Reads a single frame from a video.\n",
    "        \n",
    "        If you just want to read a single frame from the video, this is more\n",
    "        efficient than scanning through the video to find the frame. However,\n",
    "        for reading multiple frames it's not efficient.\n",
    "        \n",
    "        My guess is that a \"streaming\" approach is more efficient than a \n",
    "        \"random access\" approach because, unless you happen to grab a keyframe, \n",
    "        the decoder still needs to read all the previous frames in order to \n",
    "        reconstruct the one you're asking for.\n",
    "\n",
    "        Returns a NumPy array of shape (1, H, W, 3) and the index of the frame,\n",
    "        or None if reading failed.\n",
    "        \"\"\"\n",
    "        capture = cv2.VideoCapture(path)\n",
    "        result = self._read_frame_at_index(path, capture, frame_idx)\n",
    "        capture.release()\n",
    "        return result\n",
    "\n",
    "    def _read_frame_at_index(self, path, capture, frame_idx):\n",
    "        capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = capture.read()    \n",
    "        if not ret or frame is None:\n",
    "            if self.verbose:\n",
    "                print(\"Error retrieving frame %d from movie %s\" % (frame_idx, path))\n",
    "            return None\n",
    "        else:\n",
    "            frame = self._postprocess_frame(frame)\n",
    "            return np.expand_dims(frame, axis=0), [frame_idx]\n",
    "    \n",
    "    def _postprocess_frame(self, frame):\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         if self.insets[0] > 0:\n",
    "#             W = frame.shape[1]\n",
    "#             p = int(W * self.insets[0])\n",
    "#             frame = frame[:, p:-p, :]\n",
    "\n",
    "#         if self.insets[1] > 0:\n",
    "#             H = frame.shape[1]\n",
    "#             q = int(H * self.insets[1])\n",
    "#             frame = frame[q:-q, :, :]\n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/source/microtest/aassnaulhq.mp4',\n",
       " '../data/source/microtest/aqrsylrzgi.mp4',\n",
       " '../data/source/microtest/apvzjkvnwn.mp4',\n",
       " '../data/source/microtest/apedduehoy.mp4',\n",
       " '../data/source/microtest/aktnlyqpah.mp4',\n",
       " '../data/source/microtest/ahjnxtiamx.mp4',\n",
       " '../data/source/microtest/ayipraspbn.mp4',\n",
       " '../data/source/microtest/bcbqxhziqz.mp4',\n",
       " '../data/source/microtest/alrtntfxtd.mp4',\n",
       " '../data/source/microtest/axfhbpkdlc.mp4',\n",
       " '../data/source/microtest/bcvheslzrq.mp4',\n",
       " '../data/source/microtest/ajiyrjfyzp.mp4',\n",
       " '../data/source/microtest/adohdulfwb.mp4',\n",
       " '../data/source/microtest/acazlolrpz.mp4',\n",
       " '../data/source/microtest/aayfryxljh.mp4',\n",
       " '../data/source/microtest/aomqqjipcp.mp4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vids = glob.glob('../data/source/microtest/*')\n",
    "vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = VideoReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 3.46 s, total: 16.8 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for vid in vids:\n",
    "    vid = vr.read_frames(vid, num_frames=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 1.8 s, total: 1min 5s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for vid in vids:\n",
    "    vid = get_frames(vid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
       "       123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
       "       136, 137, 138, 140])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames = 30\n",
    "frame_ct = 300\n",
    "start = np.random.randint(frame_count-num_frames)\n",
    "np.linspace(start, start+num_frames, num=num_frames, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[164,  44,  62],\n",
       "          [166,  46,  64],\n",
       "          [144,  60,  66],\n",
       "          ...,\n",
       "          [160, 149, 142],\n",
       "          [163, 152, 145],\n",
       "          [163, 152, 145]],\n",
       " \n",
       "         [[163,  43,  61],\n",
       "          [164,  44,  62],\n",
       "          [142,  58,  64],\n",
       "          ...,\n",
       "          [154, 143, 136],\n",
       "          [156, 145, 138],\n",
       "          [156, 145, 138]],\n",
       " \n",
       "         [[151,  46,  59],\n",
       "          [152,  47,  60],\n",
       "          [133,  58,  61],\n",
       "          ...,\n",
       "          [150, 139, 132],\n",
       "          [147, 136, 129],\n",
       "          [147, 136, 129]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 72,  18,  27],\n",
       "          [ 70,  16,  25],\n",
       "          [ 69,  17,  25],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 70,  16,  25],\n",
       "          [ 69,  15,  24],\n",
       "          [ 68,  16,  24],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 70,  16,  25],\n",
       "          [ 69,  15,  24],\n",
       "          [ 68,  16,  24],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]]],\n",
       " \n",
       " \n",
       "        [[[164,  44,  62],\n",
       "          [166,  46,  64],\n",
       "          [144,  60,  66],\n",
       "          ...,\n",
       "          [160, 149, 142],\n",
       "          [163, 152, 145],\n",
       "          [163, 152, 145]],\n",
       " \n",
       "         [[163,  43,  61],\n",
       "          [164,  44,  62],\n",
       "          [142,  58,  64],\n",
       "          ...,\n",
       "          [154, 143, 136],\n",
       "          [156, 145, 138],\n",
       "          [156, 145, 138]],\n",
       " \n",
       "         [[151,  46,  59],\n",
       "          [152,  47,  60],\n",
       "          [133,  58,  61],\n",
       "          ...,\n",
       "          [150, 139, 132],\n",
       "          [147, 136, 129],\n",
       "          [147, 136, 129]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 72,  18,  27],\n",
       "          [ 70,  16,  25],\n",
       "          [ 69,  17,  25],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 70,  16,  25],\n",
       "          [ 69,  15,  24],\n",
       "          [ 68,  16,  24],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 70,  16,  25],\n",
       "          [ 69,  15,  24],\n",
       "          [ 68,  16,  24],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]]],\n",
       " \n",
       " \n",
       "        [[[ 85,  69,  54],\n",
       "          [ 90,  74,  59],\n",
       "          [ 89,  74,  63],\n",
       "          ...,\n",
       "          [141, 127, 129],\n",
       "          [137, 123, 125],\n",
       "          [135, 121, 123]],\n",
       " \n",
       "         [[ 84,  68,  53],\n",
       "          [ 88,  72,  57],\n",
       "          [ 89,  74,  63],\n",
       "          ...,\n",
       "          [151, 137, 139],\n",
       "          [147, 133, 135],\n",
       "          [146, 132, 134]],\n",
       " \n",
       "         [[ 80,  69,  54],\n",
       "          [ 84,  73,  58],\n",
       "          [ 82,  72,  60],\n",
       "          ...,\n",
       "          [156, 142, 144],\n",
       "          [155, 141, 143],\n",
       "          [155, 141, 143]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 68,  26,  29],\n",
       "          [ 68,  26,  29],\n",
       "          [ 67,  25,  28],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 69,  27,  30],\n",
       "          [ 69,  27,  30],\n",
       "          [ 68,  26,  29],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]],\n",
       " \n",
       "         [[ 71,  29,  32],\n",
       "          [ 71,  29,  32],\n",
       "          [ 68,  26,  29],\n",
       "          ...,\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8],\n",
       "          [  9,   3,   8]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 63,  69,  60],\n",
       "          [ 63,  69,  60],\n",
       "          [ 61,  67,  58],\n",
       "          ...,\n",
       "          [155, 146, 138],\n",
       "          [152, 143, 135],\n",
       "          [151, 142, 134]],\n",
       " \n",
       "         [[ 56,  62,  53],\n",
       "          [ 55,  61,  52],\n",
       "          [ 54,  60,  51],\n",
       "          ...,\n",
       "          [155, 146, 138],\n",
       "          [152, 143, 135],\n",
       "          [151, 142, 134]],\n",
       " \n",
       "         [[ 56,  64,  54],\n",
       "          [ 54,  62,  52],\n",
       "          [ 59,  67,  55],\n",
       "          ...,\n",
       "          [155, 146, 138],\n",
       "          [152, 143, 135],\n",
       "          [151, 142, 134]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 39,  26,  19],\n",
       "          [ 41,  28,  21],\n",
       "          [ 48,  30,  25],\n",
       "          ...,\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7]],\n",
       " \n",
       "         [[ 39,  26,  19],\n",
       "          [ 41,  28,  21],\n",
       "          [ 46,  28,  23],\n",
       "          ...,\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7]],\n",
       " \n",
       "         [[ 39,  26,  19],\n",
       "          [ 40,  27,  20],\n",
       "          [ 45,  27,  22],\n",
       "          ...,\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7],\n",
       "          [  6,   3,   7]]],\n",
       " \n",
       " \n",
       "        [[[ 68,  64,  86],\n",
       "          [ 74,  70,  92],\n",
       "          [ 73,  72,  89],\n",
       "          ...,\n",
       "          [140, 138, 139],\n",
       "          [145, 143, 144],\n",
       "          [152, 150, 151]],\n",
       " \n",
       "         [[ 67,  63,  85],\n",
       "          [ 73,  69,  91],\n",
       "          [ 72,  71,  88],\n",
       "          ...,\n",
       "          [141, 139, 140],\n",
       "          [145, 143, 144],\n",
       "          [151, 149, 150]],\n",
       " \n",
       "         [[ 64,  60,  82],\n",
       "          [ 69,  65,  87],\n",
       "          [ 69,  68,  85],\n",
       "          ...,\n",
       "          [145, 143, 144],\n",
       "          [146, 144, 145],\n",
       "          [150, 148, 149]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 92,  11,  29],\n",
       "          [ 91,  10,  28],\n",
       "          [ 82,  13,  27],\n",
       "          ...,\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6]],\n",
       " \n",
       "         [[ 99,   9,  30],\n",
       "          [ 99,   9,  30],\n",
       "          [ 87,  13,  29],\n",
       "          ...,\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6]],\n",
       " \n",
       "         [[101,  11,  32],\n",
       "          [101,  11,  32],\n",
       "          [ 89,  15,  31],\n",
       "          ...,\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6],\n",
       "          [ 15,   1,   6]]],\n",
       " \n",
       " \n",
       "        [[[ 70,  85,  57],\n",
       "          [ 75,  90,  62],\n",
       "          [ 72,  90,  57],\n",
       "          ...,\n",
       "          [133, 140, 135],\n",
       "          [133, 140, 135],\n",
       "          [133, 140, 135]],\n",
       " \n",
       "         [[ 72,  87,  59],\n",
       "          [ 77,  92,  64],\n",
       "          [ 73,  91,  58],\n",
       "          ...,\n",
       "          [134, 141, 136],\n",
       "          [133, 140, 135],\n",
       "          [134, 141, 136]],\n",
       " \n",
       "         [[ 70,  85,  57],\n",
       "          [ 77,  92,  64],\n",
       "          [ 73,  91,  58],\n",
       "          ...,\n",
       "          [134, 141, 136],\n",
       "          [134, 141, 136],\n",
       "          [134, 141, 136]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 46,  29,  21],\n",
       "          [ 50,  33,  25],\n",
       "          [ 49,  32,  24],\n",
       "          ...,\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6]],\n",
       " \n",
       "         [[ 46,  29,  21],\n",
       "          [ 50,  33,  25],\n",
       "          [ 49,  32,  24],\n",
       "          ...,\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6]],\n",
       " \n",
       "         [[ 48,  31,  23],\n",
       "          [ 50,  33,  25],\n",
       "          [ 50,  33,  25],\n",
       "          ...,\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6],\n",
       "          [ 13,   1,   6]]]], dtype=uint8),\n",
       " [235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  265])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
