{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd \n",
    "from tensorflow.keras.layers import ConvLSTM2D, Conv3D, Conv2D, Flatten, Dense, BatchNormalization\n",
    "import tensorflow.math as M\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from video_loader import DeepFakeDualTransformer, DeepFakeTransformer\n",
    "import sys\n",
    "import pathlib\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(bsize, None, 16, 16, 88)\n",
    "(bsize, None, 8, 8, 96)\n",
    "(2, 1)\n",
    "\"\"\"\n",
    "class FeatureDifferentiatorModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FeatureDifferentiatorModel, self).__init__()\n",
    "        self.x1_8 = ConvLSTM2D(64, (3,3), strides=(1,1), \n",
    "                            padding='same', \n",
    "                            data_format='channels_last',\n",
    "                            return_sequences=True,\n",
    "                            dropout=0.2)\n",
    "        self.x2_8 = ConvLSTM2D(128, (3,3), strides=(1,1), \n",
    "                                padding='same', \n",
    "                                data_format='channels_last',\n",
    "                                return_sequences=False,\n",
    "                                dropout=0.2)\n",
    "\n",
    "        self.x1_16 = ConvLSTM2D(64, (3,3), strides=(1,1), \n",
    "                                    padding='same', \n",
    "                                    data_format='channels_last',\n",
    "                                    return_sequences=True,\n",
    "                                    dropout=0.2)\n",
    "        self.x2_16 = ConvLSTM2D(128, (3,3), strides=(2,2), \n",
    "                            padding='same', \n",
    "                            data_format='channels_last',\n",
    "                            return_sequences=False,\n",
    "                            dropout=0.2)\n",
    "        self.x_bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.x_3 = tf.keras.layers.DepthwiseConv2D((3,3), \n",
    "                                              strides=(2,2), \n",
    "                                              depth_multiplier=2, \n",
    "                                              padding='same')\n",
    "        self.x_bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.x_4 = tf.keras.layers.DepthwiseConv2D((3,3), \n",
    "                                              strides=(2,2), \n",
    "                                              depth_multiplier=2, \n",
    "                                              padding='same')\n",
    "        self.x_5 = tf.keras.layers.Conv2D(512, (1,1), strides=(2,2))\n",
    "        self.x_bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.x_7 = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        inputs16 = inputs[0]\n",
    "        inputs8 = inputs[1]\n",
    "        x8 = self.x1_8(inputs8)\n",
    "        x8 = self.x2_8(x8)\n",
    "        x16 = self.x1_16(inputs16)\n",
    "        x16 = self.x2_16(x16)\n",
    "        x_comb = tf.keras.layers.Add()([x16, x8])\n",
    "        x = self.x_bn1(x_comb)\n",
    "        x = self.x_3(x)\n",
    "        x = self.x_bn2(x)\n",
    "        x = self.x_4(x)\n",
    "        x = self.x_5(x)\n",
    "        x = self.x_bn3(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        out = self.x_7(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'feature_differentiator_model/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeatureDifferentiatorModel()\n",
    "test_input8 = tf.keras.Input((None,8, 8, 96))\n",
    "test_input16 = tf.keras.Input(( None, 16, 16, 88))\n",
    "inputs = (test_input16, test_input8)\n",
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "for wt in model.x_bn1.get_weights():\n",
    "    print(wt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'feature_differentiator_model/batch_normalization/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'feature_differentiator_model/batch_normalization/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'feature_differentiator_model/batch_normalization/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'feature_differentiator_model/batch_normalization/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.x_bn1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_reader = tf.train.load_checkpoint('models/202032811529_bzface_model_0.2_drop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ckpt_reader.get_variable_to_dtype_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn3/moving_mean/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_8/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_4/depthwise_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn2/beta/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn1/beta/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_8/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_8/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_7/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_8/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_3/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn3/beta/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn3/gamma/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_8/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "save_counter/.ATTRIBUTES/VARIABLE_VALUE\n",
      "_CHECKPOINTABLE_OBJECT_GRAPH\n",
      "net/x_5/kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_3/depthwise_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_4/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_5/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_7/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn1/gamma/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x2_8/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn1/moving_mean/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn1/moving_variance/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x1_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn2/gamma/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn3/moving_variance/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn2/moving_variance/.ATTRIBUTES/VARIABLE_VALUE\n",
      "net/x_bn2/moving_mean/.ATTRIBUTES/VARIABLE_VALUE\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for k in d:\n",
    "    if 'OPTIMIZER' not in k and 'optimizer' not in k:\n",
    "        print(k)\n",
    "        l.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_CHECKPOINTABLE_OBJECT_GRAPH',\n",
       " 'net/x1_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x1_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x1_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x1_8/cell/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x1_8/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x1_8/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_8/cell/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_8/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x2_8/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_3/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_3/depthwise_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_4/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_4/depthwise_kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_5/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_5/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_7/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_7/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn1/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn1/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn1/moving_mean/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn1/moving_variance/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn2/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn2/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn2/moving_mean/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn2/moving_variance/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn3/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn3/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn3/moving_mean/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'net/x_bn3/moving_variance/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'save_counter/.ATTRIBUTES/VARIABLE_VALUE',\n",
       " 'step/.ATTRIBUTES/VARIABLE_VALUE']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.sort()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 64, 256)\n",
      "(3, 3, 88, 256)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(ckpt_reader.get_tensor('net/x1_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE').shape)\n",
    "print(ckpt_reader.get_tensor('net/x1_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE').shape)\n",
    "print(ckpt_reader.get_tensor('net/x1_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccur = ckpt_reader.get_tensor('net/x1_16/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE')\n",
    "kern = ckpt_reader.get_tensor('net/x1_16/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE')\n",
    "bias = ckpt_reader.get_tensor('net/x1_16/cell/bias/.ATTRIBUTES/VARIABLE_VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.x1_16.set_weights(np.array([kern, reccur, bias]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional_recurrent.ConvLSTM2D at 0x7fb90ecdfeb8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = ['x1_16', 'x1_8', 'x2_16', 'x2_8', 'x_3', 'x_4','x_5', 'x_7', 'x_bn1', 'x_bn2', 'x_bn3']\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "for layer_pre in layer_list:\n",
    "    if layer_pre in ['x1_16', 'x1_8', 'x2_16', 'x2_8']:\n",
    "        recurr_name = f'net/{layer_pre}/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        kern_name = f'net/{layer_pre}/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        bias_name = f'net/{layer_pre}/cell/bias/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        r = ckpt_reader.get_tensor(recurr_name)\n",
    "        k = ckpt_reader.get_tensor(kern_name)\n",
    "        b = ckpt_reader.get_tensor(bias_name)\n",
    "        weights_dict[layer_pre] = np.array([k, r, b])\n",
    "    elif layer_pre in ['x_3', 'x_4']:\n",
    "        kern_name = f'net/{layer_pre}/depthwise_kernel/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        bias_name = f'net/{layer_pre}/bias/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        k = ckpt_reader.get_tensor(kern_name)\n",
    "        b = ckpt_reader.get_tensor(bias_name)\n",
    "        weights_dict[layer_pre] = np.array([k, b])\n",
    "    elif layer_pre in ['x_5', 'x_7']:\n",
    "        kern_name = f'net/{layer_pre}/kernel/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        bias_name = f'net/{layer_pre}/bias/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        k = ckpt_reader.get_tensor(kern_name)\n",
    "        b = ckpt_reader.get_tensor(bias_name)\n",
    "        weights_dict[layer_pre] = np.array([k, b])\n",
    "    elif layer_pre in ['x_bn1', 'x_bn2', 'x_bn3']:\n",
    "        beta = f'net/{layer_pre}/beta/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        gamma = f'net/{layer_pre}/gamma/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        moving_mean = f'net/{layer_pre}/moving_mean/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        moving_var = f'net/{layer_pre}/moving_variance/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "        b = ckpt_reader.get_tensor(beta)\n",
    "        g = ckpt_reader.get_tensor(gamma)\n",
    "        mm = ckpt_reader.get_tensor(moving_mean)\n",
    "        mv = ckpt_reader.get_tensor(moving_var)\n",
    "        weights_dict[layer_pre] = np.array([b, g, mm, mv])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.x1_16.set_weights(weights_dict['x1_16'])\n",
    "model.x2_16.set_weights(weights_dict['x2_16'])\n",
    "model.x1_8.set_weights(weights_dict['x1_8'])\n",
    "model.x2_8.set_weights(weights_dict['x2_8'])\n",
    "model.x_3.set_weights(weights_dict['x_3'])\n",
    "model.x_4.set_weights(weights_dict['x_4'])\n",
    "model.x_5.set_weights(weights_dict['x_5'])\n",
    "model.x_7.set_weights(weights_dict['x_7'])\n",
    "model.x_bn1.set_weights(weights_dict['x_bn1'])\n",
    "model.x_bn2.set_weights(weights_dict['x_bn2'])\n",
    "model.x_bn3.set_weights(weights_dict['x_bn3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
